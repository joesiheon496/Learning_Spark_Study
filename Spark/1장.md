# 기존 모델들의 문제점
1. 번거로운 운영 복잡도
2. 일반적인 배치 처리를 위한 맵리듀스 API는 장황하고 많은 양의 기본 셋업 코드 필요 장애대응 불안정
> 맵리듀스(대용량 데이터 처리를 분산 병렬 컴퓨팅에서 처리하기 위한 목적으로 제작)
  - 맵 리듀스 과정
    - Input -> Splitting -> Mapping -> Shuffling -> Reducing -> Final Result
      - Splitting : 데이터를 쪼개어(Splitting) HDFS(Hadoop Distributed File System)에 저장하는 과정
      - Shuffling : 맵 함수의 결과를 취합하기 위해 리듀스 함수로 데이터를 전달하는 과정
      - Reducing : 모든 값을 합쳐서 우리가 원하는 값을 추출
<img width="648" alt="image" src="https://user-images.githubusercontent.com/56191064/188806120-179ffd88-30cf-425f-96a7-3656e1e7b4e3.png">

출처 : [송지현의 IT 블로그](https://songsunbi.tistory.com/5)

4. 방대한 배치 데이터 작업을 수행하면서 많은 MR태스크(맵리듀스)가 필요해지면 데이터를 로컬 디스크에 작성 필요
5. 하둡 MR은 일반적인 배치 처리를 위한 대규모 작업에는 적당하지만 머신러닝이나 스트리밍, 상호 반응하는 SQL 계통의 질의 등 다른 워크로드와 연계해 쓰기에는 한계가 있음
> 워크로드(비지니스 가치를 창출하는 리소스 및 코드모음)

# Spark 장점
1. 속도
2. 내구성, 병렬성 상승
3. 간편한 API를 다양한 언어로 제공

# 아파치 스파크란?
데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진
## 속도
### - 하드웨어의 발전
### - 질의 연산을 비순환 그래프(directed acyclic graph, DAG)로 구성
  - DAG의 스케줄러와 질의 최적화 모듈은 각각의 태스크로 분해하여 클러스터의 워커 노드 위에서 병렬 수행될 수 있도록 해줌
### - 물리엔진 텅스텐(Tungsten)
  - 전체적 코드 생성(Whole-stage code generation) 기법을 사용 간결한 코드 생성
### - 중간 결과는 메모리에 유지되며, 디스크 I/O를 제한적으로 사용하므로 성능이 크게 향상
> 디스크 I/O(Input / Output으로 컴퓨터 및 주변 장치로 데이터를 전송하는 프로그램 운영 혹은 장치)

## 사용 편리성
유연한 분산 데이터 세트(resilient distributed dataset,RDD) -> 핵심적이면서 단순한 논리 자료구조를 구축하여 단순성 실현

연산(Operation)의 종류로서 트랜스포메이션(Transformation)과 액션(Action)의 집합, 각자 편한 언어로 빅데이터 애플리케이션 만들기 가능
## 모듈성
다양한 언어 지원
## 확장성
다른 데이터 소스(다른 프레임워크?)에서 데이터 처리 가능
# 통합된 분석
통합은 스파크에 있어서 설계 철학과 진화를 나타내는 핵심 개념

## 단일화된 스택으로의 아파치 컴포넌트
API를 사용하여 스파크 어플리케이션을 만들면 스파크 코어 엔진이 적절한 DAG(Directed Acyclic Graph)로 전환해 실행한다.

## 스파크 SQL
CSV, JSON, ORC 데이터로 영구적이거나 임시적인 테이블 만들기 가능

또한 자바, 파이썬 ,스칼라, R 등으로 스카픜 정형화 API를 사용하여 SQL 계통의 질의를 써서 데이터를 바로 데이터 프레임으로 읽기 가능

## 스파크 MLlib
MLlib은 모델을 구축하기 위한 고수준 데이터 프레임 기반 API 기반으로 여러 인기 있는 머신러닝 알고리즘을 제공

```python
from pyspark.ml.classification import LogisticRegression

training = spark.read_csv("s3://")
test = spark.read_csv("s3://")

# 훈련 데이터 로드
lr = LogisticRegression(maxIter = 10, regParam = 0.3, elasticNetParam = 0.8)

# 모델 적합화(fit)
lrModel = lr.fit(training)

# 예측
lrModel.transform(text)
```

## 스파크 정형화 스트리밍
정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리하면서 개발자들에게는 상대적으로 쉽게 스트리밍 애플리케이션을 작성하도록 도움

정형화 스트리밍 애플리케이션의 형태
```python
# 파이썬 예제
# 로컬 호스트에서 스트림을 읽어들임
from pyspark.sql.functions import explode, split
lines = (spark
  .readStream
  .format("socket")
  .option("host","localhost")
  .option("port","9999)
  .load())
# 트랜스포메이션 수행
# 라이별로 읽어 단어별로 나눔
words = lines.select(explode(split(lines.value, " ")).alias("word"))

# 단어 세기를 수행
word_counts = words.groupBy("word").count()

# 결과 스트림을 카프카에 사용
query = (word_counts
  .writeStram
  .format("kafka")
  .oprion("topic","output))
```
> 카프카 : 분산 환경에서 사용되는 데이터 스트리밍 플랫폼이고, 오픈소스를 특징으로 하며, 실시간 스트림의 처리 등에서 활용되는 솔루션
### graphX
그래프를 조작(예: SNS 친구 관계 그래프, 경로, 연결점, 네트워크망 구성 그래프 등) 그래프 병렬 연산을 수행하기 위한 라이브러리

페이지랭크, 연결 컴포넌트, 삼각 집계 등의 알고리즘도 포함

## 아파치 스파크의 분산 실행
스파크의 분산 아키텍처 위에서 모든 컴포넌트들이 같이 동작하면서 서로 통신하는지, 어떤 식으로 배포가 가능한지 알아볼 필요있음
> 컴포넌트 : 여러 개의 프로그램 함수들을 모아 하나의 특정한 기능을 수행할 수 있도록 구성한 작은 기능적 단위

스파크 아키텍처를 넓은 범위에서 보면, 하나의 스파크 애플리케이션은 스파크 클러스터의 병렬 작업들을 조율하는 하나의 드라이버 프로그램으로 이루어진다.

드라이버는 SparkSession 객체를 통해 클러스터의 분산 컴포넌트들에 접근한다.

### 스파크 드라이버
SparkSession 객체를 초기화하는 책임을 가진 스파크 애플리케이션의 일부

- 클러스터 매니저와 통신하며 스파크 이그제큐터들을 위해 필요한 자원을 요청(CPU,메모리 등) 
- 모든 스파크 작업을 DAG연산 형태로 변환하고 스케줄링
- 각 실행 단위를 태스크로 나누어 스파크 이그제큐터들에게 분배
- 자원이 할당된 후 드라이버는 이그제큐터와 직접 통신

![image](https://user-images.githubusercontent.com/56191064/189037482-4ed25db1-a4d3-4ed3-87dc-1fe9bc2f2628.png)
> 스파크의 구성 요소는 크게 드라이버(driver)와 이그제큐터(executor) 2가지다. 드라이버는 사용자의 코드를 여러 작업자 노드로 배분할 수 있는 여러 작업으로 변환하고 이그제큐터는 이런 노드에서 실행되면서 할당된 작업을 실행한다. 그리고 이 둘을 중재하기 위한 클러스터 관리자가 필요 [출처](https://www.itworld.co.kr/news/147556#csidxd097f7afd9f9038a3a319c6997742a8)

### SparkSession
모든 스파크 연산과 데이터에 대한 통합 연결 채널
  - 실행 파라미터 생성 가능
  - 데이터 프레임이나 데이터세트를 정의
  - 데이터 소스에서 데이터 읽기
  - 메타데이터에 접근해 스파크 SQL 질의 실행가능

### 클러스터 매니저
스파크 애플리케이션이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 지님

네종류의 클러스터 매니저를 지원
  - 내장 단독 클러스터 매니저
  - 아파치 하둡 얀
  - 아파치 메소스
  - 쿠버네티스

### 스파크 이그제큐터
클러스터의 각 워커 노드에서 동작

이그제큐터는 클러스터의 각 워커 노드에서 동작한다.

이그제큐터는 드라이버 프로그램과 통신하며 워커에서 태스크를 실행하는 역할을 한다

대부분의 배포 모드에서 노드당 하나의 이그제큐터만이 실행

### 배포모드
여러 다른 환경에서 다른 설정으로 돌아갈 수 있도록 다양한 배포 모드를 지원
|모드|스파크 드라이버|스파크 이그제큐터|클러스터 매니저|
|------|---------------|-----------------|-------------|
|로컬|랩톱이나 단일 서버 같은 머신에서 단일 JVM 위에서 실행|드라이버와 동일한 JVM 위에서 동작|동일한 호스트에서 실행|
|단독|클러스터의 아무 노드에서나 실행 가능|클러스터의 각 노드가 자체적인 이그제큐터 JVM을 실행|클러스터의 아무 호스트에나 할당 가능|
|얀(클라이언트)|클러스터 외부의 클라이언트에서 동작|얀의 노드매니저와 컨테이너|얀의 리소스 매니저가 얀의 애플리케이션 마스터와 연계하여 노드 매니저에 이그제큐터를 위한 컨테이너들을 할당|
|얀(클러스터)|얀 애플리케이션 마스터에서 동작|얀(클러스터) 모드와 동일||얀(클러스터) 모드와 동일|
|쿠버네티스|쿠버네티스 팟에서 동작| 각 워커가 자신의 팟 내에서 실행|쿠버네티스 마스터|

### 분산 데이터와 파티션
실제 물리적인 데이터는 HDFS나 클라우드 저장소에 존재하는 파티션이 되어 저장소 전체에 분산된다
  1. 데이터가 파티션으로 되어 물리적으로 분산
  2. 스파크는 각 파티션을 고수준(?)에서 논리적인 데이터 추상화 -> 메모리의 데이터 프레임 객체로
  3. 항상 가능한 것은 아니지만, 각 스파크 이그제큐터는 가급적이면 데이터 지역성을 고려하여 네트워크에서 가장 가까운 파티션을 읽어 들이도록 태스크를 할당

파티셔닝은 효과적인 병렬처리를 가능하게 해준다. 

데이터를 조각내어 청크나 파티션으로 분산해 저장하는 방식은 스파크 이그제큐터가 네트워크 사용을 최소화하며 가까이 있는 데이터만 처리할 수 있도록 해준다.

-> 이그제큐터가 쓰는 CPU 코어는 작업해야 하는 데이터의 파티션에 할당하게 된다
