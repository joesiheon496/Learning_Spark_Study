# 기존 모델들의 문제점
1. 번거로운 운영 복잡도
2. 일반적인 배치 처리를 위한 맵리듀스(대용량 데이터 처리를 분산 병렬 컴퓨팅에서 처리하기 위한 목적으로 제작)API는 장황하고 많은 양의 기본 셋업 코드 필요 장애대응 불안정
  - 맵 리듀스 과정
    - Input -> Splitting -> Mapping -> Shuffling -> Reducing -> Final Result
      - Splitting : 데이터를 쪼개어(Splitting) HDFS(Hadoop Distributed File System)에 저장하는 과정
      - Shuffling : 맵 함수의 결과를 취합하기 위해 리듀스 함수로 데이터를 전달하는 과정
      - Reducing : 모든 값을 합쳐서 우리가 원하는 값을 추출
<img width="648" alt="image" src="https://user-images.githubusercontent.com/56191064/188806120-179ffd88-30cf-425f-96a7-3656e1e7b4e3.png">

출처 : [송지현의 IT 블로그](https://songsunbi.tistory.com/5)

4. 방대한 배치 데이터 작업을 수행하면서 많은 MR태스크(맵리듀스)가 필요해지면 데이터를 로컬 디스크에 작성 필요
5. 하둡 MR은 일반적인 배치 처리를 위한 대규모 작업에는 적당하지만 머신러닝이나 스트리밍, 상호 반응하는 SQL 계통의 질의 등 다른 워크로드(비지니스 가치를 창출하는 리소스 및 코드모음)와 연계해 쓰기에는 한계가 있음

# Spark 장점
1. 속도
2. 내구성, 병렬성 상승
3. 간편한 API를 다양한 언어로 제공

# 아파치 스파크란?
데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진
## 속도
### 하드웨어의 발전
### 질의 연산을 비순환 그래프(directed acyclic graph, DAG)로 구성
  - DAG의 스케줄러와 질의 최적화 모듈은 각각의 태스크로 분해하여 클러스터의 워커 노드 위에서 병렬 수행될 수 있도록 해줌
### 물리엔진 텅스텐(Tungsten)
  - 전체적 코드 생성(Whole-stage code generation) 기법을 사용 간결한 코드 생성
### 중간 결과는 메모리에 유지되며, 디스크 I/O(Input / Output으로 컴퓨터 및 주변 장치로 데이터를 전송하는 프로그램 운영 혹은 장치)를 제한적으로 사용하므로 성능이 크게 향상

### 사용 편리성
유연한 분산 데이터 세트(resilient distributed dataset,RDD) -> 핵심적이면서 단순한 논리 자료구조를 구축하여 단순성 실현

연산(Operation)의 종류로서 트랜스포메이션(Transformation)과 액션(Action)의 집합, 각자 편한 언어로 빅데이터 애플리케이션 만들기 가능
### 모듈성
다양한 언어 지원
### 확장성
다른 데이터 소스(다른 프레임워크?)에서 데이터 처리 가능
## 통합된 분석

